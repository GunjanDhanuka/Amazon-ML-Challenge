{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport csv\nimport math\nimport os\nimport random\nimport time\nimport copy\nfrom tqdm.notebook import tqdm\nimport multiprocessing\nimport yaml\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nfrom transformers import AutoModel, AutoTokenizer\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import AdamW\nfrom transformers import DataCollatorWithPadding, DefaultDataCollator","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:02:34.812822Z","iopub.execute_input":"2023-04-20T20:02:34.813194Z","iopub.status.idle":"2023-04-20T20:02:47.322592Z","shell.execute_reply.started":"2023-04-20T20:02:34.813160Z","shell.execute_reply":"2023-04-20T20:02:47.321527Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ['TRANSFORMERS_NO_ADVISORY_WARNINGS'] = 'true'","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:02:47.326685Z","iopub.execute_input":"2023-04-20T20:02:47.327363Z","iopub.status.idle":"2023-04-20T20:02:47.335545Z","shell.execute_reply.started":"2023-04-20T20:02:47.327333Z","shell.execute_reply":"2023-04-20T20:02:47.334390Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# import wandb\n\n# try:\n#     from kaggle_secrets import UserSecretsClient\n#     user_secrets = UserSecretsClient()\n#     api_key = user_secrets.get_secret(\"wandb_api\")\n#     wandb.login(key=api_key)\n#     anony = None\n# except:\n#     anony = \"must\"\n#     print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:02:47.337371Z","iopub.execute_input":"2023-04-20T20:02:47.338115Z","iopub.status.idle":"2023-04-20T20:02:47.346937Z","shell.execute_reply.started":"2023-04-20T20:02:47.338077Z","shell.execute_reply":"2023-04-20T20:02:47.345997Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class Config:\n    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n    model_name = \"microsoft/deberta-v3-base\"\n    model_save_name = \"best_model.pth\"\n    train_batch_size = 16\n    valid_batch_size = 16\n    grad_max_norm = 10\n    grad_acc = 1\n    epochs = 1\n    hidden_size = 768\n    collate_fn = None\n    weight_decay = 0.01\n    lr = 1e-4\n    seed = 42\n    max_len = 64\n    num_workers = 2\n\nconfig = Config()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:02:47.350955Z","iopub.execute_input":"2023-04-20T20:02:47.351221Z","iopub.status.idle":"2023-04-20T20:02:47.419051Z","shell.execute_reply.started":"2023-04-20T20:02:47.351196Z","shell.execute_reply":"2023-04-20T20:02:47.417881Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(config.model_name)\nbase_model = AutoModel.from_pretrained(config.model_name)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:02:47.420767Z","iopub.execute_input":"2023-04-20T20:02:47.421228Z","iopub.status.idle":"2023-04-20T20:02:53.748553Z","shell.execute_reply.started":"2023-04-20T20:02:47.421188Z","shell.execute_reply":"2023-04-20T20:02:53.747576Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"406f15c9b78e4df2bc3ddd25c083793c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"deabdb62ad71457e8fd3b46030a92a7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2100ff6492b54003bebc41cc41717a81"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:447: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d9cc26407eb41099142340f142078e2"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight']\n- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"config.collate_fn = DataCollatorWithPadding(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:03:02.765787Z","iopub.execute_input":"2023-04-20T20:03:02.766163Z","iopub.status.idle":"2023-04-20T20:03:02.771792Z","shell.execute_reply.started":"2023-04-20T20:03:02.766129Z","shell.execute_reply":"2023-04-20T20:03:02.770769Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# set seed\ndef set_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nset_seed(config.seed)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:03:03.855685Z","iopub.execute_input":"2023-04-20T20:03:03.856059Z","iopub.status.idle":"2023-04-20T20:03:03.866015Z","shell.execute_reply.started":"2023-04-20T20:03:03.856028Z","shell.execute_reply":"2023-04-20T20:03:03.864870Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/amazon-ml/dataset/train.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:03:04.614190Z","iopub.execute_input":"2023-04-20T20:03:04.614554Z","iopub.status.idle":"2023-04-20T20:05:49.955789Z","shell.execute_reply.started":"2023-04-20T20:03:04.614522Z","shell.execute_reply":"2023-04-20T20:05:49.954651Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   PRODUCT_ID                                              TITLE  \\\n0     1925202  ArtzFolio Tulip Flowers Blackout Curtain for D...   \n1     2673191  Marks & Spencer Girls' Pyjama Sets T86_2561C_N...   \n2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n4      283658  The United Empire Loyalists: A Chronicle of th...   \n\n                                       BULLET_POINTS  \\\n0  [LUXURIOUS & APPEALING: Beautiful custom-made ...   \n1  [Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...   \n2  [Loud Dual Tone Trumpet Horn, Compatible With ...   \n3  [Made By 95%cotton and 5% Lycra which gives yo...   \n4                                                NaN   \n\n                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n0                                                NaN             1650   \n1                                                NaN             2755   \n2  Specifications: Color: Red, Material: Aluminiu...             7537   \n3  AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n4                                                NaN             6112   \n\n   PRODUCT_LENGTH  \n0     2125.980000  \n1      393.700000  \n2      748.031495  \n3      787.401574  \n4      598.424000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRODUCT_ID</th>\n      <th>TITLE</th>\n      <th>BULLET_POINTS</th>\n      <th>DESCRIPTION</th>\n      <th>PRODUCT_TYPE_ID</th>\n      <th>PRODUCT_LENGTH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1925202</td>\n      <td>ArtzFolio Tulip Flowers Blackout Curtain for D...</td>\n      <td>[LUXURIOUS &amp; APPEALING: Beautiful custom-made ...</td>\n      <td>NaN</td>\n      <td>1650</td>\n      <td>2125.980000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2673191</td>\n      <td>Marks &amp; Spencer Girls' Pyjama Sets T86_2561C_N...</td>\n      <td>[Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...</td>\n      <td>NaN</td>\n      <td>2755</td>\n      <td>393.700000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2765088</td>\n      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n      <td>7537</td>\n      <td>748.031495</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1594019</td>\n      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n      <td>2996</td>\n      <td>787.401574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>283658</td>\n      <td>The United Empire Loyalists: A Chronicle of th...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6112</td>\n      <td>598.424000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"target_column = \"PRODUCT_LENGTH\"","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:05:49.958007Z","iopub.execute_input":"2023-04-20T20:05:49.958465Z","iopub.status.idle":"2023-04-20T20:05:49.965026Z","shell.execute_reply.started":"2023-04-20T20:05:49.958426Z","shell.execute_reply":"2023-04-20T20:05:49.963030Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"text = train['TITLE'].values[np.random.randint(0, len(train) - 1, 1)[0]]\nprint(f\"Text of the title: {text}\")\n\nencoded_input = tokenizer(text, return_tensors='pt')\nprint(f\"Input tokens: {encoded_input['input_ids']}\")\n\ndecoded_input = tokenizer.decode(encoded_input['input_ids'][0])\nprint(f\"Decoded tokens: {decoded_input}\")\n\nwith torch.no_grad():\n    output = base_model(**encoded_input)\nprint(f\"last layer's output shape: {output.last_hidden_state.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:05:49.966283Z","iopub.execute_input":"2023-04-20T20:05:49.967246Z","iopub.status.idle":"2023-04-20T20:05:50.415311Z","shell.execute_reply.started":"2023-04-20T20:05:49.967207Z","shell.execute_reply":"2023-04-20T20:05:50.414242Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Text of the title: PUDINI® for Vivo V23 PRO 5G Leather Holster Pouch Belt Clip Cases Waist Bag Pack for [Up to 6.5 Inch] Phone Holder - Black\nInput tokens: tensor([[     1, 110060,  59206,   2139,    270,  35194,   1407,   3304,  12535,\n            456,   1474,   9348,  96989,  50131,  11397,  22247,  24773,  38277,\n           8296,   8019,    270,    647,   9396,    264,    525,    260,    524,\n          19891,    592,   7151,  16996,    341,   1552,      2]])\nDecoded tokens: [CLS] PUDINI® for Vivo V23 PRO 5G Leather Holster Pouch Belt Clip Cases Waist Bag Pack for [Up to 6.5 Inch] Phone Holder - Black[SEP]\nlast layer's output shape: torch.Size([1, 34, 768])\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_folds(data, num_splits):\n    data[\"kfold\"] = -1\n    data = data.sample(frac=1).reset_index(drop=True)\n    y = data['PRODUCT_TYPE_ID']\n    kf = StratifiedKFold(n_splits=num_splits)\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=y)):\n        data.loc[v_, 'kfold'] = f\n    return data\n  \ntrain = create_folds(train, 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_subset = train[train['PRODUCT_LENGTH']<10000]\ntrain_subset.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:06:19.390422Z","iopub.execute_input":"2023-04-20T20:06:19.391082Z","iopub.status.idle":"2023-04-20T20:06:19.756678Z","shell.execute_reply.started":"2023-04-20T20:06:19.391032Z","shell.execute_reply":"2023-04-20T20:06:19.755525Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(2229490, 6)"},"metadata":{}}]},{"cell_type":"code","source":"train_subset['PRODUCT_LENGTH'] = train_subset['PRODUCT_LENGTH']/100","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:06:21.757668Z","iopub.execute_input":"2023-04-20T20:06:21.758309Z","iopub.status.idle":"2023-04-20T20:06:21.784292Z","shell.execute_reply.started":"2023-04-20T20:06:21.758275Z","shell.execute_reply":"2023-04-20T20:06:21.783189Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, data, tokenizer, mode=\"train\", max_length=None):\n        super(TextDataset, self).__init__()\n        self.sentence = data[\"TITLE\"].values\n        if mode != \"test\":\n            self.label = data[target_column].values\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.mode = mode\n\n    def __len__(self):\n        return len(self.sentence)\n\n    def __getitem__(self,idx):\n        inp_tokens = self.tokenizer(self.sentence[idx], \n                                              padding=False, \n                                              add_special_tokens=True,\n                                              max_length=self.max_length,\n                                              truncation=True)\n        item={\n            \"input_ids\":torch.tensor(inp_tokens.input_ids,dtype=torch.long),\n            \"attention_mask\":torch.tensor(inp_tokens.attention_mask,dtype=torch.long)\n        }\n\n        if self.mode != \"test\":\n            item['labels'] = torch.tensor(self.label[idx], dtype=torch.long)\n\n        return item","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:23:01.058994Z","iopub.execute_input":"2023-04-20T20:23:01.059975Z","iopub.status.idle":"2023-04-20T20:23:01.069673Z","shell.execute_reply.started":"2023-04-20T20:23:01.059919Z","shell.execute_reply":"2023-04-20T20:23:01.068629Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class ArcMarginProduct(nn.Module):\n    r\"\"\"Implement of large margin arc distance: :\n        Args:\n            in_features: size of each input sample\n            out_features: size of each output sample\n            s: norm of input feature\n            m: margin\n            cos(theta + m)\n        \"\"\"\n    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, input, label):\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt((1.0 - torch.pow(cosine, 2)).clamp(0, 1))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------------\n        one_hot = torch.zeros(cosine.size(), device=config.device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)  # you can use torch.where if your torch.__version__ is 0.4\n        output *= self.s\n        # print(output)\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:06:23.158062Z","iopub.execute_input":"2023-04-20T20:06:23.158657Z","iopub.status.idle":"2023-04-20T20:06:23.170172Z","shell.execute_reply.started":"2023-04-20T20:06:23.158618Z","shell.execute_reply":"2023-04-20T20:06:23.168990Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, \n                 base_model, \n                 last_hidden_size=config.hidden_size):\n        \n        super().__init__()\n        self.base_model = base_model\n#         self.arc_margin = ArcMarginProduct(last_hidden_size, \n#                                            num_classes, \n#                                            s=30.0, \n#                                            m=0.50, \n#                                            easy_margin=False)\n        \n        self.fc = nn.Linear(in_features=last_hidden_size, out_features=1)\n    \n\n    \n    def forward(self, batch):\n        out = self.base_model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n        last_hidden_state = out.last_hidden_state # shape: (batch_size, seq_length, bert_hidden_dim)\n        attention_mask = batch['attention_mask']\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        logits = self.fc(mean_embeddings)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:06:23.811316Z","iopub.execute_input":"2023-04-20T20:06:23.811780Z","iopub.status.idle":"2023-04-20T20:06:23.820134Z","shell.execute_reply.started":"2023-04-20T20:06:23.811746Z","shell.execute_reply":"2023-04-20T20:06:23.818980Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"class AvgMeter:\n    def __init__(self, name=\"Metric\"):\n        self.name = name\n        self.reset()\n    \n    def reset(self):\n        self.avg, self.sum, self.count = [0]*3\n    \n    def update(self, val, count=1):\n        self.count += count\n        self.sum += val * count\n        self.avg = self.sum / self.count\n    \n    def __repr__(self):\n        text = f\"{self.name}: {self.avg:.4f}\"\n        return text\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:06:27.685528Z","iopub.execute_input":"2023-04-20T20:06:27.686252Z","iopub.status.idle":"2023-04-20T20:06:27.692743Z","shell.execute_reply.started":"2023-04-20T20:06:27.686211Z","shell.execute_reply":"2023-04-20T20:06:27.691655Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def one_epoch(model, criterion, dataloader, epoch, scaler=None, optimizer=None, scheduler=None, mode='train'):\n    \n    loss_meter = AvgMeter()\n    \n    bar = tqdm(dataloader, total=len(dataloader))\n    \n    for idx, batch in enumerate(bar):\n        batch = {k: v.to(config.device) for k, v in batch.items()}\n        \n        with torch.autocast(device_type='cuda', dtype=torch.float16):\n            preds = model(batch)\n            \n        loss = criterion(preds, batch['labels'].unsqueeze(-1))\n        \n        if mode == \"train\":\n            loss = loss/config.grad_acc\n            scaler.scale(loss).backward()\n            if (idx+1)%config.grad_acc==0 or (idx+1)==len(dataloader):\n                scaler.unscale_(optimizer)\n                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_max_norm)\n                scaler.step(optimizer)\n                scaler.update()\n                for param in model.parameters():\n                    param.grad = None\n\n            if scheduler:\n                scheduler.step()\n                \n        count = batch['input_ids'].shape[0]\n        loss_meter.update(loss.item(), count)\n        \n        \n        if mode == \"train\":\n            bar.set_postfix(epoch=epoch, train_loss=loss_meter.avg, lr=get_lr(optimizer))\n        else:\n            bar.set_postfix(epoch=epoch, valid_loss=loss_meter.avg)\n    \n    return loss_meter, acc_meter\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group[\"lr\"]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:06:37.567397Z","iopub.execute_input":"2023-04-20T20:06:37.568177Z","iopub.status.idle":"2023-04-20T20:06:37.580768Z","shell.execute_reply.started":"2023-04-20T20:06:37.568139Z","shell.execute_reply":"2023-04-20T20:06:37.578970Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def train_eval(epochs, model, train_loader, valid_loader, \n               criterion, optimizer, scheduler=None, scaler=None):\n    \n    best_loss = np.inf\n    best_model_weights = copy.deepcopy(model.state_dict())\n    \n    for epoch in range(epochs):\n        print(f\"Epoch {epoch + 1}\")\n        \n        model.train()\n        train_loss, train_acc = one_epoch(model, \n                                          criterion, \n                                          train_loader, \n                                          epoch,\n                                          scaler,\n                                          optimizer=optimizer,\n                                          scheduler=scheduler,\n                                          mode=\"train\")                     \n        model.eval()\n        with torch.no_grad():\n            valid_loss, valid_acc = one_epoch(model, \n                                              criterion, \n                                              valid_loader, \n                                              epoch,\n                                              optimizer=None,\n                                              scheduler=None,\n                                              mode=\"valid\")\n        \n        if valid_loss.avg < best_loss:\n            best_loss = valid_loss.avg\n            best_model_weights = copy.deepcopy(model.state_dict())\n            torch.save(model.state_dict(), f'{config.model_save_name}')\n            print(\"Saved best model!\")\n        \n        print(\"=\" * 30)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:06:39.582913Z","iopub.execute_input":"2023-04-20T20:06:39.583857Z","iopub.status.idle":"2023-04-20T20:06:39.593008Z","shell.execute_reply.started":"2023-04-20T20:06:39.583799Z","shell.execute_reply":"2023-04-20T20:06:39.591653Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def optimizer_params(model, config=config):\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': config.weight_decay},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n    ]\n    return optimizer_parameters","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:06:40.914474Z","iopub.execute_input":"2023-04-20T20:06:40.915163Z","iopub.status.idle":"2023-04-20T20:06:40.921819Z","shell.execute_reply.started":"2023-04-20T20:06:40.915124Z","shell.execute_reply":"2023-04-20T20:06:40.920650Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_sample = train_subset.sample(frac=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:06:41.854560Z","iopub.execute_input":"2023-04-20T20:06:41.855475Z","iopub.status.idle":"2023-04-20T20:06:42.236603Z","shell.execute_reply.started":"2023-04-20T20:06:41.855435Z","shell.execute_reply":"2023-04-20T20:06:42.235530Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_sample.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:06:42.479636Z","iopub.execute_input":"2023-04-20T20:06:42.480004Z","iopub.status.idle":"2023-04-20T20:06:42.487667Z","shell.execute_reply.started":"2023-04-20T20:06:42.479970Z","shell.execute_reply":"2023-04-20T20:06:42.486430Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(1114745, 6)"},"metadata":{}}]},{"cell_type":"code","source":"train_df, valid_df = train_test_split(train_sample, \n                                      test_size=0.33, \n                                      shuffle=True, \n                                      random_state=config.seed)\n\ntrain_df=train_df.reset_index(drop=True)\nvalid_df=valid_df.reset_index(drop=True)\n\ntrain_dataset = TextDataset(train_df, tokenizer, max_length=config.max_len)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, \n                                           batch_size=16, \n                                           num_workers=config.num_workers, \n                                           shuffle=True,\n                                          collate_fn=config.collate_fn, \n                                          pin_memory=True)\n\nvalid_dataset = TextDataset(valid_df, tokenizer, max_length=config.max_len)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, \n                                           batch_size=config.valid_batch_size, \n                                           num_workers=config.num_workers, \n                                           shuffle=False,\n                                          collate_fn=config.collate_fn,\n                                          pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:23:08.294682Z","iopub.execute_input":"2023-04-20T20:23:08.295066Z","iopub.status.idle":"2023-04-20T20:23:08.800477Z","shell.execute_reply.started":"2023-04-20T20:23:08.295034Z","shell.execute_reply":"2023-04-20T20:23:08.799325Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model = Model(base_model).to(config.device)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:07:30.517246Z","iopub.execute_input":"2023-04-20T20:07:30.517667Z","iopub.status.idle":"2023-04-20T20:07:30.724918Z","shell.execute_reply.started":"2023-04-20T20:07:30.517626Z","shell.execute_reply":"2023-04-20T20:07:30.723851Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"num_steps = int(len(train_loader)*config.epochs/config.train_batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:07:31.937290Z","iopub.execute_input":"2023-04-20T20:07:31.937887Z","iopub.status.idle":"2023-04-20T20:07:31.949306Z","shell.execute_reply.started":"2023-04-20T20:07:31.937848Z","shell.execute_reply":"2023-04-20T20:07:31.947330Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"criterion = nn.L1Loss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\nscheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(0.3*num_steps), num_training_steps=num_steps)\nscaler = torch.cuda.amp.GradScaler()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:07:49.751672Z","iopub.execute_input":"2023-04-20T20:07:49.752072Z","iopub.status.idle":"2023-04-20T20:07:49.759698Z","shell.execute_reply.started":"2023-04-20T20:07:49.752040Z","shell.execute_reply":"2023-04-20T20:07:49.758406Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_eval(config.epochs, model, train_loader, valid_loader,\n           criterion, optimizer, scheduler=scheduler, scaler=scaler)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:23:28.159944Z","iopub.execute_input":"2023-04-20T20:23:28.160404Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/46680 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee8957cda7b84fb39bf1e4d2c9ef5252"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}