{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os, gc, re, warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-20T21:18:01.871755Z","iopub.execute_input":"2023-04-20T21:18:01.872290Z","iopub.status.idle":"2023-04-20T21:18:01.903137Z","shell.execute_reply.started":"2023-04-20T21:18:01.872231Z","shell.execute_reply":"2023-04-20T21:18:01.902107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dftr = pd.read_csv(\"/kaggle/input/amazon-ml/dataset/train.csv\")\ndftr[\"src\"]=\"train\"\ndfte = pd.read_csv(\"/kaggle/input/amazon-ml/dataset/test.csv\")\ndfte[\"src\"]=\"test\"\nprint('Train shape:',dftr.shape,'Test shape:',dfte.shape,'Test columns:',dfte.columns)\ndf = pd.concat([dftr,dfte],ignore_index=True)\n\ndftr.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T21:18:01.907458Z","iopub.execute_input":"2023-04-20T21:18:01.907742Z","iopub.status.idle":"2023-04-20T21:18:51.115204Z","shell.execute_reply.started":"2023-04-20T21:18:01.907715Z","shell.execute_reply":"2023-04-20T21:18:51.114030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dftr.shape)\ndftr = dftr.dropna(axis=0, subset=['TITLE'])\nprint(dftr.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T21:22:38.867165Z","iopub.execute_input":"2023-04-20T21:22:38.867652Z","iopub.status.idle":"2023-04-20T21:22:39.277124Z","shell.execute_reply.started":"2023-04-20T21:22:38.867614Z","shell.execute_reply":"2023-04-20T21:22:39.275955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dftr.fillna(\"\", inplace=True)\ndfte.fillna(\"\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T21:53:46.800286Z","iopub.execute_input":"2023-04-20T21:53:46.801305Z","iopub.status.idle":"2023-04-20T21:53:47.862120Z","shell.execute_reply.started":"2023-04-20T21:53:46.801264Z","shell.execute_reply":"2023-04-20T21:53:47.861009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dftr.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T21:56:23.782398Z","iopub.execute_input":"2023-04-20T21:56:23.783162Z","iopub.status.idle":"2023-04-20T21:56:24.322831Z","shell.execute_reply.started":"2023-04-20T21:56:23.783115Z","shell.execute_reply":"2023-04-20T21:56:24.321657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfte.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T21:56:31.408865Z","iopub.execute_input":"2023-04-20T21:56:31.409582Z","iopub.status.idle":"2023-04-20T21:56:31.596089Z","shell.execute_reply.started":"2023-04-20T21:56:31.409541Z","shell.execute_reply":"2023-04-20T21:56:31.594890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfte.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-20T21:59:37.571910Z","iopub.execute_input":"2023-04-20T21:59:37.572929Z","iopub.status.idle":"2023-04-20T21:59:37.579400Z","shell.execute_reply.started":"2023-04-20T21:59:37.572888Z","shell.execute_reply":"2023-04-20T21:59:37.578290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_cols = ['PRODUCT_LENGTH']","metadata":{"execution":{"iopub.status.busy":"2023-04-20T21:53:47.896090Z","iopub.execute_input":"2023-04-20T21:53:47.896903Z","iopub.status.idle":"2023-04-20T21:53:47.901475Z","shell.execute_reply.started":"2023-04-20T21:53:47.896861Z","shell.execute_reply":"2023-04-20T21:53:47.900336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import sys\n# sys.path.append('../input/iterativestratification')\n# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n# FOLDS = 25\n# skf = MultilabelStratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n# for i,(train_index, val_index) in enumerate(skf.split(dftr,dftr[target_cols])):\n#     dftr.loc[val_index,'FOLD'] = i\n# print('Train samples per fold:')\n# dftr.FOLD.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T21:18:51.124352Z","iopub.execute_input":"2023-04-20T21:18:51.124713Z","iopub.status.idle":"2023-04-20T21:18:51.132083Z","shell.execute_reply.started":"2023-04-20T21:18:51.124676Z","shell.execute_reply":"2023-04-20T21:18:51.130972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Embeddings","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel,AutoTokenizer, DataCollatorWithPadding\nimport torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-04-20T21:53:52.241201Z","iopub.execute_input":"2023-04-20T21:53:52.241923Z","iopub.status.idle":"2023-04-20T21:53:52.247686Z","shell.execute_reply.started":"2023-04-20T21:53:52.241883Z","shell.execute_reply":"2023-04-20T21:53:52.246434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output.last_hidden_state.detach().cpu()\n    input_mask_expanded = (\n        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    )\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n        input_mask_expanded.sum(1), min=1e-9\n    )","metadata":{"execution":{"iopub.status.busy":"2023-04-20T21:53:52.277851Z","iopub.execute_input":"2023-04-20T21:53:52.278158Z","iopub.status.idle":"2023-04-20T21:53:52.284045Z","shell.execute_reply.started":"2023-04-20T21:53:52.278128Z","shell.execute_reply":"2023-04-20T21:53:52.282893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 4\ntokenizer = None\nMAX_LEN = 128\n\nclass EmbedDataset(torch.utils.data.Dataset):\n    def __init__(self,df):\n        self.df = df.reset_index(drop=True)\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,idx):\n        text = self.df.loc[idx,\"TITLE\"]\n        tokens = tokenizer(\n                text,\n                None,\n                add_special_tokens=True,\n                padding=False,\n                truncation=True,\n                max_length=32,return_tensors=\"pt\")\n        tokens = {k:v.squeeze(0) for k,v in tokens.items()}\n        return tokens\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T22:08:11.169815Z","iopub.execute_input":"2023-04-20T22:08:11.170347Z","iopub.status.idle":"2023-04-20T22:08:11.196582Z","shell.execute_reply.started":"2023-04-20T22:08:11.170308Z","shell.execute_reply":"2023-04-20T22:08:11.195470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(MODEL_NM='', MAX=640, BATCH_SIZE=4, verbose=True):\n    global tokenizer, MAX_LEN\n    DEVICE=\"cuda\"\n    model = AutoModel.from_pretrained( MODEL_NM )\n    tokenizer = AutoTokenizer.from_pretrained( MODEL_NM )\n    MAX_LEN = MAX\n    \n    ds_tr = EmbedDataset(dftr)\n    embed_dataloader_tr = torch.utils.data.DataLoader(ds_tr,\\\n                        batch_size=BATCH_SIZE,\\\n                        shuffle=False, collate_fn=DataCollatorWithPadding(tokenizer))\n    ds_te = EmbedDataset(dfte)\n    embed_dataloader_te = torch.utils.data.DataLoader(ds_te,\\\n                        batch_size=BATCH_SIZE,\\\n                        shuffle=False, collate_fn=DataCollatorWithPadding(tokenizer))\n    \n    model = model.to(DEVICE)\n    model.eval()\n    all_train_text_feats = []\n    for batch in tqdm(embed_dataloader_tr,total=len(embed_dataloader_tr)):\n        input_ids = batch[\"input_ids\"].to(DEVICE)\n        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n        with torch.no_grad():\n            model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n        sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n        # Normalize the embeddings\n        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n        sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n        all_train_text_feats.extend(sentence_embeddings)\n    all_train_text_feats = np.array(all_train_text_feats)\n    if verbose:\n        print('Train embeddings shape',all_train_text_feats.shape)\n        \n    te_text_feats = []\n    for batch in tqdm(embed_dataloader_te,total=len(embed_dataloader_te)):\n        input_ids = batch[\"input_ids\"].to(DEVICE)\n        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n        with torch.no_grad():\n            model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n        sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n        # Normalize the embeddings\n        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n        sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n        te_text_feats.extend(sentence_embeddings)\n    te_text_feats = np.array(te_text_feats)\n    if verbose:\n        print('Test embeddings shape',te_text_feats.shape)\n        \n    return all_train_text_feats, te_text_feats","metadata":{"execution":{"iopub.status.busy":"2023-04-20T22:08:12.622989Z","iopub.execute_input":"2023-04-20T22:08:12.623720Z","iopub.status.idle":"2023-04-20T22:08:12.638528Z","shell.execute_reply.started":"2023-04-20T22:08:12.623681Z","shell.execute_reply":"2023-04-20T22:08:12.637413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NM = '../input/huggingface-deberta-variants/deberta-base/deberta-base'\nall_train_text_feats, te_text_feats = get_embeddings(MODEL_NM, MAX=32, BATCH_SIZE=32)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T22:08:52.902510Z","iopub.execute_input":"2023-04-20T22:08:52.903332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('train_deberta_base_feats.npy', all_train_text_feats)\nnp.save('test_deberta_base_feats.npy', te_text_feats)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del all_train_text_feats, te_text_feats\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NM = '../input/deberta-v3-large/deberta-v3-large'\nall_train_text_feats2, te_text_feats2 = get_embeddings(MODEL_NM, MAX=32, BATCH_SIZE=32)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('train_deberta_largev3_feats.npy', all_train_text_feats2)\nnp.save('test_deberta_largev3_feats.npy', te_text_feats2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del all_train_text_feats2, te_text_feats2\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]}]}